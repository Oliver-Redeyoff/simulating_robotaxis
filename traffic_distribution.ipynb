{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import math\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from enum import Enum\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import folium\n",
    "import xml.etree.ElementTree as ET\n",
    "import utm\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from pyproj import Transformer\n",
    "from shapely.geometry import shape, Point\n",
    "import http.client as httplib\n",
    "import urllib.parse as urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare dataclasses\n",
    "\n",
    "Coord = Tuple[float, float]\n",
    "\n",
    "@dataclass\n",
    "class lane:\n",
    "    id: str\n",
    "    speed: float\n",
    "    shape: List[Coord]\n",
    "    allow: List[str]\n",
    "    disallow: List[str]\n",
    "\n",
    "@dataclass\n",
    "class edge:\n",
    "    id: str\n",
    "    is_drivable: bool\n",
    "    lanes: List[lane]\n",
    "\n",
    "@dataclass\n",
    "class count():\n",
    "    hour: int\n",
    "    value_sum: int\n",
    "    value_count: int\n",
    "\n",
    "@dataclass\n",
    "class count_point():\n",
    "    id: str\n",
    "    road_name: str\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    utm: any\n",
    "    counts: List[count]\n",
    "    closest_lane: Tuple[float, lane]\n",
    "\n",
    "@dataclass\n",
    "class taz:\n",
    "    id: str\n",
    "    name: str\n",
    "    edges: List[str]\n",
    "    drivable_edges: List[str]\n",
    "    node_count: int\n",
    "    weight: float\n",
    "    area: float\n",
    "\n",
    "@dataclass\n",
    "class simulation:\n",
    "    start_time: int\n",
    "    end_time: int\n",
    "    duration: int\n",
    "\n",
    "@dataclass\n",
    "class trip:\n",
    "    id: int\n",
    "    depart: float\n",
    "    from_: str\n",
    "    to: str\n",
    "    def __lt__(self, other):\n",
    "         return self.depart < other.depart\n",
    "\n",
    "@dataclass\n",
    "class commuter:\n",
    "    home_edge: edge\n",
    "    destination_edge: edge\n",
    "    trip1: trip\n",
    "    trip2: trip\n",
    "\n",
    "@dataclass\n",
    "class tripinfo:\n",
    "    trip_id: int\n",
    "    duration: float\n",
    "    waiting_time: float\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1**: get data and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class p(Enum):\n",
    "    count_point_id = 0\n",
    "    direction_of_travel = 1\n",
    "    year = 2\n",
    "    count_date = 3\n",
    "    hour = 4\n",
    "    region_id = 5\n",
    "    region_name = 6\n",
    "    local_authority_id = 7\n",
    "    local_authority_name = 8\n",
    "    road_name = 9\n",
    "    road_type = 10\n",
    "    start_junction_road_name = 11\n",
    "    end_junction_road_name = 12\n",
    "    easting = 13\n",
    "    northing = 14\n",
    "    latitude = 15\n",
    "    longitude = 16\n",
    "    link_length_km = 17\n",
    "    link_length_miles = 18\n",
    "    pedal_cycles = 19\n",
    "    two_wheeled_motor_vehicles = 20\n",
    "    cars_and_taxis = 21\n",
    "    buses_and_coaches = 22\n",
    "    lgvs = 23\n",
    "    hgvs_2_rigid_axle = 24\n",
    "    hgvs_3_rigid_axle = 25\n",
    "    hgvs_4_or_more_rigid_axle = 26\n",
    "    hgvs_3_or_4_articulated_axle = 27\n",
    "    hgvs_5_articulated_axle = 28\n",
    "    hgvs_6_articulated_axle = 29\n",
    "    all_hgvs = 30\n",
    "    all_motor_vehicles = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get name of target, and get it's position using google maps places api\n",
    "\n",
    "target_name = input(\"Enter town name : \");\n",
    "\n",
    "x = requests.get('https://maps.googleapis.com/maps/api/geocode/json?address=' + target_name + '&key=AIzaSyAhmPLZ2MEGQK1-7rTmyjbN_r6Pnqjr8YM')\n",
    "res = json.loads(x.text)\n",
    "\n",
    "target_geometry = res['results'][0]['geometry']\n",
    "target_bbox = target_geometry['viewport']\n",
    "m = folium.Map(location=[target_geometry['location']['lat'], target_geometry['location']['lng']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download appropriate osm data\n",
    "\n",
    "def readCompressed(conn, urlpath, query, filename):\n",
    "    conn.request(\"POST\", \"/\" + urlpath, \"\"\"\n",
    "    <osm-script timeout=\"240\" element-limit=\"1073741824\">\n",
    "    <union>\n",
    "       %s\n",
    "       <recurse type=\"node-relation\" into=\"rels\"/>\n",
    "       <recurse type=\"node-way\"/>\n",
    "       <recurse type=\"way-relation\"/>\n",
    "    </union>\n",
    "    <union>\n",
    "       <item/>\n",
    "       <recurse type=\"way-node\"/>\n",
    "    </union>\n",
    "    <print mode=\"body\"/>\n",
    "    </osm-script>\"\"\" % query)\n",
    "    response = conn.getresponse()\n",
    "    print(response.status, response.reason)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as out:\n",
    "            out.write(response.read())\n",
    "\n",
    "url = urlparse.urlparse(\"https://www.overpass-api.de/api/interpreter\")\n",
    "conn = httplib.HTTPConnection(url.hostname, url.port)\n",
    "readCompressed(\n",
    "   conn, \n",
    "   url.path, \n",
    "   '<bbox-query n=\"{n}\" s=\"{s}\" w=\"{w}\" e=\"{e}\"/>'.format(\n",
    "      n=target_bbox['northeast']['lat'], \n",
    "      s=target_bbox['southwest']['lat'], \n",
    "      w=target_bbox['southwest']['lng'],\n",
    "      e=target_bbox['northeast']['lng']), \n",
    "   \"target.osm.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out which local authority the town is in\n",
    "\n",
    "with open('local_authorities.geojson', 'r') as myfile:\n",
    "    local_authorities_raw = myfile.read()\n",
    "local_authorities = json.loads(local_authorities_raw)\n",
    "\n",
    "transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:3857\")\n",
    "target_position = Point(transformer.transform(target_geometry['location']['lat'], target_geometry['location']['lng']))\n",
    "local_authority_id = 0\n",
    "\n",
    "for local_authority in local_authorities['features']:\n",
    "    multipolygon = shape(local_authority['geometry'])\n",
    "    if multipolygon.contains(target_position):\n",
    "        local_authority_id = local_authority['properties']['id']\n",
    "        print(\"Found target area in \" + local_authority['properties']['Name'])\n",
    "\n",
    "if (local_authority_id == 0):\n",
    "    print(\"ERROR: could not find area in any british local authority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count point data for relevant local authority\n",
    "\n",
    "x = requests.get('https://storage.googleapis.com/dft-statistics/road-traffic/downloads/rawcount/local_authority_id/dft_rawcount_local_authority_id_' + str(local_authority_id) + '.csv');\n",
    "raw_counts = x.text.split('\\n');\n",
    "raw_counts = list(csv.reader(raw_counts));\n",
    "list.pop(raw_counts);\n",
    "raw_counts.pop(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce each count for a point at a certain time of day into one average value\n",
    "\n",
    "# only include points from 2018\n",
    "raw_counts = [point for point in raw_counts if point[p.year.value]=='2018'];\n",
    "\n",
    "# now reduce all values to single averages for each time of day\n",
    "count_points: List[count_point] = []\n",
    "\n",
    "def aggregate_counts(count_point_: count_point, raw_count):\n",
    "\n",
    "    for count_ in count_point_.counts:\n",
    "        if (count_.hour == int(raw_count[p.hour.value])):\n",
    "            # add count to average\n",
    "            count_.value_sum += int(raw_count[p.cars_and_taxis.value])\n",
    "            count_.value_count += 1\n",
    "            return\n",
    "\n",
    "    count_point_.counts.append(count(\n",
    "        int(raw_count[p.hour.value]),\n",
    "        int(raw_count[p.cars_and_taxis.value]),\n",
    "        1\n",
    "    ))\n",
    "\n",
    "\n",
    "# reduce raw counts to average count at each count point\n",
    "for raw_count in raw_counts:\n",
    "\n",
    "    count_point_id = raw_count[p.count_point_id.value];\n",
    "    \n",
    "    # need to define count_point if it hasn't been added yet\n",
    "    if (count_point_id not in [point.id for point in count_points]):\n",
    "        new_count_point = count_point(\n",
    "            count_point_id,\n",
    "            raw_count[p.road_name.value],\n",
    "            float(raw_count[p.latitude.value]),\n",
    "            float(raw_count[p.longitude.value]),\n",
    "            utm.from_latlon(float(raw_count[p.latitude.value]), float(raw_count[p.longitude.value])),\n",
    "            [],\n",
    "            (-1, None)\n",
    "        )\n",
    "        aggregate_counts(new_count_point, raw_count)\n",
    "        count_points.append(new_count_point)\n",
    "\n",
    "    else:\n",
    "        for count_point_ in count_points:\n",
    "            if (count_point_.id == count_point_id):\n",
    "                aggregate_counts(count_point_, raw_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2**: generate network and deduce TAZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sumo network and deduce TAZs using the saga tool\n",
    "\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    sys.path.append(os.path.join(os.environ['SUMO_HOME'], 'tools/contributed/saga'))\n",
    "    import scenarioFromOSM\n",
    "else:\n",
    "    sys.exit(\"please declare environment variable 'SUMO_HOME'\")\n",
    "\n",
    "saga_options = ['--osm', 'target.osm.xml',\n",
    "            '--out', './temp_saga',\n",
    "            '--from-step', str(0),\n",
    "            '--to-step', str(7),\n",
    "            '--lefthand']\n",
    "            \n",
    "scenarioFromOSM.main(saga_options)\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "shutil.copyfile('./temp_saga/osm.net.xml', './target.net.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all edges and their UTM position\n",
    "\n",
    "net_tree = ET.parse('target.net.xml')\n",
    "net_root = net_tree.getroot()\n",
    "\n",
    "# get origin UTM position\n",
    "temp1 = net_root[0].attrib['projParameter'].split(' ')\n",
    "utm_zone = int(temp1[1].split('=')[1])\n",
    "\n",
    "origin = net_root[0].attrib['netOffset'].split(',')\n",
    "origin = [-1*float(coord) for coord in origin]\n",
    "\n",
    "edges: List[edge] = []\n",
    "\n",
    "def normalise_shape(shape_str):\n",
    "     shape = [list(map(float, point.split(\",\"))) for point in shape_str.split(\" \")]\n",
    "     for point in shape:\n",
    "          point[0] += origin[0]\n",
    "          point[1] += origin[1]\n",
    "\n",
    "     return shape\n",
    "\n",
    "\n",
    "for edge_element in tqdm(net_root.findall('edge'), desc='Extracting lanes'):\n",
    "\n",
    "     # instantiate new edge\n",
    "     new_edge = edge(\n",
    "          edge_element.attrib['id'],\n",
    "          False,\n",
    "          []\n",
    "     )\n",
    "\n",
    "     # instantiate all new lanes\n",
    "     for lane_element in edge_element.findall('lane'):\n",
    "          new_lane = lane(\n",
    "               lane_element.attrib['id'],\n",
    "               float(lane_element.attrib['speed']),\n",
    "               normalise_shape(lane_element.attrib['shape']),\n",
    "               lane_element.attrib['allow'].split(' ') if 'allow' in lane_element.attrib else [],\n",
    "               lane_element.attrib['disallow'].split(' ') if 'disallow' in lane_element.attrib else []\n",
    "          )\n",
    "          if (new_lane.allow and 'passenger' in new_lane.allow):\n",
    "                new_edge.is_drivable = True\n",
    "          elif (new_lane.disallow and 'passenger' not in new_lane.disallow):\n",
    "               new_edge.is_drivable = True\n",
    "          new_edge.lanes.append(new_lane)\n",
    "     \n",
    "     edges.append(new_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve tazs and their weights\n",
    "\n",
    "tazs: List[taz] = []\n",
    "\n",
    "taz_tree = ET.parse('./temp_saga/osm_taz.xml')\n",
    "taz_root = taz_tree.getroot()\n",
    "taz_total_weight = 0\n",
    "\n",
    "drivable_edges = set([edge_.id for edge_ in edges if edge_.is_drivable])\n",
    "\n",
    "# instantiate tazs\n",
    "for taz_ in tqdm(taz_root):\n",
    "    tazs.append(taz(\n",
    "        taz_.attrib['id'],\n",
    "        '',\n",
    "        taz_.attrib['edges'].split(' '),\n",
    "        list(drivable_edges.intersection(set(taz_.attrib['edges'].split(' ')))),\n",
    "        0,\n",
    "        0,\n",
    "        0\n",
    "    ))\n",
    "\n",
    "with open('./temp_saga/osm_taz_weight.csv', mode='r') as csv_taz_weights:\n",
    "    csv_reader = csv.DictReader(csv_taz_weights)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        taz_ = next(taz_ for taz_ in tazs if taz_.id == row['TAZ'])\n",
    "        taz_.name = row['Name']\n",
    "        taz_.node_count = int(row['#Nodes'])\n",
    "        taz_.area = float(row['Area'])\n",
    "\n",
    "# filter out taz which don't have any drivable edges\n",
    "tazs = [taz_ for taz_ in tazs if len(taz_.drivable_edges)>0]\n",
    "\n",
    "# for taz_ in tazs:\n",
    "#     print(taz_.name + \": \" + str(len(taz_.drivable_edges)) + \" and \" + str(len(taz_.edges)))\n",
    "\n",
    "taz_total_node_count = sum(taz_.node_count for taz_ in tazs)\n",
    "for taz_ in tazs:\n",
    "    taz_.weight = taz_.node_count/taz_total_node_count\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3**: associate count points with lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each count point, work out the closest lane from the utm position\n",
    "\n",
    "def min_dist_to_lane(lane_: lane, count_point_: count_point) -> float:\n",
    "\n",
    "    min_dist = -1;\n",
    "\n",
    "    for i in range(1, len(lane_.shape)):\n",
    "        x = count_point_.utm[0];\n",
    "        y = count_point_.utm[1];\n",
    "        x1 = lane_.shape[i-1][0];\n",
    "        y1 = lane_.shape[i-1][1];\n",
    "        x2 = lane_.shape[i][0];\n",
    "        y2 = lane_.shape[i][1];\n",
    "\n",
    "        A = x - x1;\n",
    "        B = y - y1;\n",
    "        C = x2 - x1;\n",
    "        D = y2 - y1;\n",
    "\n",
    "        dot = A * C + B * D;\n",
    "        len_sq = C * C + D * D;\n",
    "        param = -1;\n",
    "        if (len_sq != 0):\n",
    "            param = dot / len_sq;\n",
    "\n",
    "        xx = 0.0;\n",
    "        yy = 0.0;\n",
    "\n",
    "        if (param < 0):\n",
    "            xx = x1;\n",
    "            yy = y1;\n",
    "        elif (param > 1):\n",
    "            xx = x2;\n",
    "            yy = y2;\n",
    "        else:\n",
    "            xx = x1 + param * C;\n",
    "            yy = y1 + param * D;\n",
    "\n",
    "        dx = x - xx;\n",
    "        dy = y - yy;\n",
    "        dist = math.sqrt(dx * dx + dy * dy);\n",
    "\n",
    "        if (min_dist == -1 or dist<min_dist):\n",
    "            min_dist = dist;\n",
    "    \n",
    "    return min_dist;\n",
    "\n",
    "# find closest lane for each count_point\n",
    "for count_point_ in tqdm(count_points):\n",
    "    closest_lane: Tuple[float, lane] = (-1, None);\n",
    "    \n",
    "    for edge_ in edges:\n",
    "        for lane_ in edge_.lanes:\n",
    "            dist = min_dist_to_lane(lane_, count_point_);\n",
    "            if (closest_lane[0] == -1 or dist<closest_lane[0]):\n",
    "                closest_lane = (dist, lane_);\n",
    "    \n",
    "    count_point_.closest_lane = closest_lane;\n",
    "\n",
    "    # lane_start_utm = closest_lane[1].shape[0];\n",
    "    # lane_start = utm.to_latlon(lane_start_utm[0], lane_start_utm[1], utm_zone, northern=True);\n",
    "\n",
    "# filter out count points which are more that 10 metres away from the closest lane\n",
    "count_points = [count_point_ for count_point_ in count_points if count_point_.closest_lane[0]<10];\n",
    "\n",
    "# place markers for each counting point on map\n",
    "for count_point_ in count_points:\n",
    "    folium.Marker([float(count_point_.latitude), float(count_point_.longitude)], popup=count_point_.id, icon=folium.Icon(color=\"red\")).add_to(m);\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 4**: generate mobility demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate traffic distribution based on count point data\n",
    "\n",
    "simulation_ = simulation(23, 0, 0)\n",
    "\n",
    "aggregated_counts = [{'sum': 0, 'count': 0, 'average': 0, 'distribution_value': 0} for i in range(1, 23)];\n",
    "\n",
    "# aggregate count point data by time\n",
    "for count_point_ in count_points:\n",
    "    for count_ in count_point_.counts:\n",
    "        hour = count_.hour\n",
    "\n",
    "        if (hour < simulation_.start_time):\n",
    "            simulation_.start_time = hour\n",
    "        if (hour > simulation_.end_time):\n",
    "            simulation_.end_time = hour\n",
    "\n",
    "        aggregated_counts[count_.hour]['sum'] += count_.value_sum\n",
    "        aggregated_counts[count_.hour]['count'] += count_.value_count\n",
    "\n",
    "simulation_.duration = (simulation_.end_time-simulation_.start_time)*3600\n",
    "\n",
    "# calculate distribution from aggregated data\n",
    "total = 0;\n",
    "for hour_count in aggregated_counts:\n",
    "    if hour_count['count'] != 0:\n",
    "        hour_count['average'] = hour_count['sum']/hour_count['count']\n",
    "        total += hour_count['average']\n",
    "\n",
    "for idx, hour_count in enumerate(aggregated_counts):\n",
    "    if hour_count['count'] != 0:\n",
    "        hour_count['distribution_value'] = hour_count['average']/total\n",
    "\n",
    "plt.plot([count['distribution_value'] for count in aggregated_counts])\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get population and deduce number of people who will need trips\n",
    "\n",
    "def indent(elem, level=0):\n",
    "    i = \"\\n\" + level*\"  \"\n",
    "    if len(elem):\n",
    "        if not elem.text or not elem.text.strip():\n",
    "            elem.text = i + \"  \"\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "        for elem in elem:\n",
    "            indent(elem, level+1)\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "    else:\n",
    "        if level and (not elem.tail or not elem.tail.strip()):\n",
    "            elem.tail = i\n",
    "\n",
    "def get_random_drivable_edge() -> edge:\n",
    "    if (random.random() <= 0.5):\n",
    "        rand = random.random()\n",
    "        ac_weight = 0\n",
    "        for taz_ in tazs:\n",
    "            ac_weight += taz_.weight\n",
    "            if (rand <= ac_weight):\n",
    "                edge_id = random.choice(taz_.drivable_edges)\n",
    "                return next(edge_ for edge_ in edges if edge_.id == edge_id)\n",
    "    else:\n",
    "        edge_id = random.choice(list(drivable_edges))\n",
    "        return next(edge_ for edge_ in edges if edge_.id == edge_id)\n",
    "        \n",
    "population = 100000\n",
    "commuter_percentage = 0.25\n",
    "total_commuters = round(population*commuter_percentage)\n",
    "total_trips = total_commuters*2\n",
    "\n",
    "commuters: List[commuter] = [commuter('', '', None, None) for i in range(total_commuters)]\n",
    "for commuter_ in tqdm(commuters):\n",
    "    commuter_.home_edge = get_random_drivable_edge()\n",
    "    commuter_.destination_edge = get_random_drivable_edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for commuter_ in commuters:\n",
    "    commuter_.trip1 = None\n",
    "    commuter_.trip2 = None\n",
    "\n",
    "# For each hour, generate trips\n",
    "trip_id = 0\n",
    "for hour in tqdm(range(simulation_.start_time, simulation_.end_time+1)):\n",
    "    trip_count = math.floor(total_trips * aggregated_counts[hour]['distribution_value'])\n",
    "    generated_trip_count = 0\n",
    "    processed_commuters = []\n",
    "\n",
    "    while generated_trip_count != trip_count:\n",
    "        commuter_ = random.choice(commuters)\n",
    "        if (commuter_ in processed_commuters):\n",
    "            continue\n",
    "        \n",
    "        if (commuter_.trip1 == None):\n",
    "            commuter_.trip1 = trip(\n",
    "                trip_id,\n",
    "                float(hour*3600 + round(random.random()*3600)),\n",
    "                commuter_.home_edge.id,\n",
    "                commuter_.destination_edge.id\n",
    "            )\n",
    "        elif (commuter_.trip2 == None):\n",
    "            commuter_.trip2 = trip(\n",
    "                trip_id,\n",
    "                float(hour*3600 + round(random.random()*3600)),\n",
    "                commuter_.destination_edge.id,\n",
    "                commuter_.home_edge.id\n",
    "            )\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        generated_trip_count += 1\n",
    "        trip_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_routes_root = ET.Element(\"routes\")\n",
    "\n",
    "for commuter_ in tqdm(commuters):\n",
    "    if(commuter_.trip1):\n",
    "        ET.SubElement(base_routes_root, 'trip', {\n",
    "            'id': str(commuter_.trip1.id), \n",
    "            'depart': str(commuter_.trip1.depart),\n",
    "            'from': commuter_.trip1.from_,\n",
    "            'to': commuter_.trip1.to\n",
    "        })\n",
    "    if(commuter_.trip2):\n",
    "        ET.SubElement(base_routes_root, 'trip', {\n",
    "            'id': str(commuter_.trip2.id), \n",
    "            'depart': str(commuter_.trip2.depart),\n",
    "            'from': commuter_.trip2.from_,\n",
    "            'to': commuter_.trip2.to\n",
    "        })\n",
    "\n",
    "base_routes_tree = ET.ElementTree(base_routes_root)\n",
    "indent(base_routes_root)\n",
    "base_routes_tree.write(\"base_target.trips.xml\", encoding=\"utf-8\", xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate routes using the duarouter tool\n",
    "\n",
    "duarouter_options = ['duarouter',\n",
    "                    '--net-file', 'target.net.xml',\n",
    "                    '--route-files', 'base_target.trips.xml',\n",
    "                    '--output-file', 'base_target.routes.xml',\n",
    "                    '--ignore-errors', 'true',\n",
    "                    '--repair', 'true',\n",
    "                    '--unsorted-input', 'true',\n",
    "                    '--no-warnings', 'true']\n",
    "                    \n",
    "subprocess.check_call(duarouter_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate taxi mobility definition\n",
    "\n",
    "taxi_count = 0\n",
    "\n",
    "taxi_routes_root = ET.Element(\"routes\")\n",
    "\n",
    "taxi_def = ET.SubElement(taxi_routes_root, 'vType', {\n",
    "    'id': 'route_0',\n",
    "    'edges': random.choice(list(drivable_edges))\n",
    "})\n",
    "ET.SubElement(taxi_routes_root, 'route', {\n",
    "    'id': 'taxi',\n",
    "    'vClass': 'taxi'\n",
    "})\n",
    "ET.SubElement(taxi_def, 'param', {\n",
    "    'key': 'has.taxi.device',\n",
    "    'value': 'true'\n",
    "})\n",
    "\n",
    "all_trips: List[trip] = []\n",
    "all_trips.extend([commuter_.trip1 for commuter_ in commuters if commuter_.trip1 != None])\n",
    "all_trips.extend([commuter_.trip2 for commuter_ in commuters if commuter_.trip2 != None])\n",
    "all_trips.sort()\n",
    "\n",
    "for taxi_id in range(taxi_count):\n",
    "    taxi_vehicle = ET.SubElement(taxi_routes_root, 'vehicle', {\n",
    "        'id': 'v'+str(taxi_id), \n",
    "        'depart': str(simulation_.start_time*3600) + '.00',\n",
    "        'type': 'taxi',\n",
    "        'line': 'taxi'\n",
    "    })\n",
    "    ET.SubElement(taxi_vehicle, 'route', {\n",
    "        'edges': random.choice(list(drivable_edges))\n",
    "    })\n",
    "\n",
    "person_id = 0\n",
    "# for trip_ in tqdm(all_trips):\n",
    "#     taxi_vehicle = ET.SubElement(taxi_routes_root, 'person', {\n",
    "#         'id': 'p'+str(person_id), \n",
    "#         'depart': str(trip_.depart),\n",
    "#         'color': 'green'\n",
    "#     })\n",
    "#     ET.SubElement(taxi_vehicle, 'ride', {\n",
    "#         'from': trip_.from_,\n",
    "#         'to': trip_.to,\n",
    "#         'lines': 'taxi'\n",
    "#     })\n",
    "#     person_id += 1\n",
    "\n",
    "taxi_vehicle = ET.SubElement(taxi_routes_root, 'person', {\n",
    "    'id': 'p'+str(person_id), \n",
    "    'depart': str(all_trips[0].depart),\n",
    "    'color': 'green'\n",
    "})\n",
    "ET.SubElement(taxi_vehicle, 'ride', {\n",
    "    'from': all_trips[0].from_,\n",
    "    'to': all_trips[0].to,\n",
    "    'lines': 'taxi'\n",
    "})\n",
    "\n",
    "taxi_routes_tree = ET.ElementTree(taxi_routes_root)\n",
    "indent(taxi_routes_root)\n",
    "taxi_routes_tree.write(\"taxi_target.trips.xml\", encoding=\"utf-8\", xml_declaration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 5**: Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation using the sumo program\n",
    "\n",
    "sumo_options = ['sumo',\n",
    "                '--configuration-file', 'target.sumocfg',\n",
    "                # '--emission-output', './out/target.emissions.xml',\n",
    "                # '--statistic-output', './out/target.stats.xml',\n",
    "                '--tripinfo-output', './out/base_target.tripinfo.xml']\n",
    "\n",
    "# subprocess.check_call(sumo_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the results of the simulation\n",
    "\n",
    "tripinfos: List[tripinfo] = []\n",
    "\n",
    "tripinfo_tree = ET.parse('./out/base_target.tripinfo.xml')\n",
    "tripinfo_root = tripinfo_tree.getroot()\n",
    "\n",
    "for tripinfo_ in tqdm(tripinfo_root):\n",
    "    new_tripinfo = tripinfo(\n",
    "        int(tripinfo_.attrib['id']),\n",
    "        float(tripinfo_.attrib['duration']),\n",
    "        float(tripinfo_.attrib['waitingTime'])\n",
    "    )\n",
    "    tripinfos.append(new_tripinfo)\n",
    "\n",
    "print(len(tripinfos))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
